{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082c2de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T00:00:53.969275Z",
     "iopub.status.busy": "2024-10-23T00:00:53.968983Z",
     "iopub.status.idle": "2024-10-23T00:00:54.255470Z",
     "shell.execute_reply": "2024-10-23T00:00:54.254451Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.29799,
     "end_time": "2024-10-23T00:00:54.256963",
     "exception": false,
     "start_time": "2024-10-23T00:00:53.958973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6459cf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T00:00:54.277683Z",
     "iopub.status.busy": "2024-10-23T00:00:54.277377Z",
     "iopub.status.idle": "2024-10-23T00:00:58.044590Z",
     "shell.execute_reply": "2024-10-23T00:00:58.043571Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.781478,
     "end_time": "2024-10-23T00:00:58.046099",
     "exception": false,
     "start_time": "2024-10-23T00:00:54.264621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/bin/load-spark-env.sh: line 68: ps: command not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/23 00:00:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .config(\"spark.pyspark.python\", \"C:/Users/alexa/AppData/Local/Programs/Python/Python39/python.exe\") \\\n",
    "    .config(\"spark.pyspark.driver.python\", \"C:/Users/alexa/AppData/Local/Programs/Python/Python39/python.exe\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5619f200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T00:00:58.075813Z",
     "iopub.status.busy": "2024-10-23T00:00:58.074588Z",
     "iopub.status.idle": "2024-10-23T00:01:02.665502Z",
     "shell.execute_reply": "2024-10-23T00:01:02.664529Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 4.612183,
     "end_time": "2024-10-23T00:01:02.666680",
     "exception": false,
     "start_time": "2024-10-23T00:00:58.054497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Caminho para o arquivo JSON\n",
    "bronze_path = '/opt/airflow/bronze_layer/breweries_raw.json'\n",
    "\n",
    "df = spark.read.json(bronze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033b14a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T00:01:02.682839Z",
     "iopub.status.busy": "2024-10-23T00:01:02.682581Z",
     "iopub.status.idle": "2024-10-23T00:01:02.686456Z",
     "shell.execute_reply": "2024-10-23T00:01:02.685528Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01526,
     "end_time": "2024-10-23T00:01:02.687645",
     "exception": false,
     "start_time": "2024-10-23T00:01:02.672385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caminho para salvar o DataFrame no formato parquet\n",
    "silver_path = '/opt/airflow/silver_layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251f2ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T00:01:02.704519Z",
     "iopub.status.busy": "2024-10-23T00:01:02.704267Z",
     "iopub.status.idle": "2024-10-23T00:01:10.917111Z",
     "shell.execute_reply": "2024-10-23T00:01:10.916162Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 8.225203,
     "end_time": "2024-10-23T00:01:10.918386",
     "exception": false,
     "start_time": "2024-10-23T00:01:02.693183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados transformados e salvos em /opt/airflow/silver_layer\n"
     ]
    }
   ],
   "source": [
    "df.write.mode('append') \\\n",
    "    .partitionBy('state', 'country') \\\n",
    "    .parquet(silver_path)\n",
    "\n",
    "print(f\"Dados transformados e salvos em {silver_path}\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.521764,
   "end_time": "2024-10-23T00:01:13.543727",
   "environment_variables": {},
   "exception": null,
   "input_path": "/opt/airflow/jobs/python/silver/transform_data.ipynb",
   "output_path": "/opt/airflow/jobs/python/silver/transformed_data_output.ipynb",
   "parameters": {},
   "start_time": "2024-10-23T00:00:52.021963",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}